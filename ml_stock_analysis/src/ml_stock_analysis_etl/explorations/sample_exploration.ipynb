{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19a992e9-55e0-49e4-abc7-8c92c420dd5b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Example Exploratory Notebook\n",
    "\n",
    "Use this notebook to explore the data generated by the pipeline in your preferred programming language.\n",
    "\n",
    "**Note**: This notebook is not executed as part of the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f361c04-4a7f-4b1f-ac22-dd91eaf112fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"NSE_Daily_Data\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"200\") \\\n",
    "    .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "625c8705-1a80-4e50-ba33-73dfd82948a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "url = \"https://www.nseindia.com/api/equity-stockIndices?index=NIFTY%2050\"\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0\",\n",
    "    \"Accept\": \"application/json\",\n",
    "    \"Referer\": \"https://www.nseindia.com\"\n",
    "}\n",
    "\n",
    "session = requests.Session()\n",
    "session.get(\"https://www.nseindia.com\", headers=headers)  # create cookies\n",
    "\n",
    "r = session.get(url, headers=headers)\n",
    "\n",
    "print(\"Status:\", r.status_code)\n",
    "\n",
    "data = r.json()\n",
    "df = pd.DataFrame(data[\"data\"])\n",
    "df[\"date\"] = datetime.today().strftime('%Y-%m-%d')\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b77b9a50-602e-4e5e-8905-7a80253d4ef1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # spark.sql(\"CREATE SCHEMA IF NOT EXISTS workspace.NSE_SET\")\n",
    "# spark.sql(\"\"\"\n",
    "#     CREATE TABLE IF NOT EXISTS workspace.NSE_SET.NIFTY50_DAILY (\n",
    "#         priority              BIGINT,\n",
    "#         symbol                STRING,\n",
    "#         identifier            STRING,\n",
    "#         open                  DOUBLE,\n",
    "#         dayHigh               DOUBLE,\n",
    "#         dayLow                DOUBLE,\n",
    "#         lastPrice             DOUBLE,\n",
    "#         previousClose         DOUBLE,\n",
    "#         change                DOUBLE,\n",
    "#         pChange               DOUBLE,\n",
    "#         ffmc                  DOUBLE,\n",
    "#         yearHigh              DOUBLE,\n",
    "#         yearLow               DOUBLE,\n",
    "#         totalTradedVolume     BIGINT,\n",
    "#         stockIndClosePrice    BIGINT,\n",
    "#         totalTradedValue      DOUBLE,\n",
    "#         lastUpdateTime        STRING,\n",
    "#         nearWKH               DOUBLE,\n",
    "#         nearWKL               DOUBLE,\n",
    "#         perChange365d         DOUBLE,\n",
    "#         perChange30d          DOUBLE,\n",
    "#         date365dAgo           STRING,\n",
    "#         date30dAgo            STRING,\n",
    "#         chartTodayPath        STRING,\n",
    "#         chart30dPath          STRING,\n",
    "#         chart365dPath         STRING,\n",
    "#         series                STRING,\n",
    "#         meta                  STRING,\n",
    "#         trade_date            date,\n",
    "#         load_date             date\n",
    "#     )\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d630e31c-d8b9-462e-ba98-a61524cddbb3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit, current_date\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Ensure 'meta' column is cast to StringType to avoid type inference error\n",
    "if \"meta\" in df.columns:\n",
    "    df[\"meta\"] = df[\"meta\"].astype(str)\n",
    "\n",
    "spark_df = spark.createDataFrame(df)\n",
    "spark_df = spark_df.withColumnRenamed(\"date\", \"trade_date\").withColumn(\"load_date\", current_date())\n",
    "\n",
    "# Delete rows with the same load_date before inserting new data\n",
    "# load_date_value = spark_df.select(\"load_date\").first()\n",
    "# if load_date_value is not None:\n",
    "#     load_date_value = load_date_value[\"load_date\"]\n",
    "#     spark.sql(f\"DELETE FROM workspace.NSE_SET.NIFTY50_DAILY WHERE load_date = DATE('{load_date_value}')\")\n",
    "\n",
    "spark_df.write.mode(\"append\").insertInto(\"workspace.NSE_SET.NIFTY50_DAILY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e697863-970d-41b9-ae72-9847f9d4f3b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "dependencies": [
     "-r /Workspace/Users/girianiruddha4@gmail.com/stck_data/ml_stock_analysis/src/ml_stock_analysis_etl/requirements.txt"
    ],
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5971364465630979,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "sample_exploration",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
