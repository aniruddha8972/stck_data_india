{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19a992e9-55e0-49e4-abc7-8c92c420dd5b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Example Exploratory Notebook\n",
    "\n",
    "Use this notebook to explore the data generated by the pipeline in your preferred programming language.\n",
    "\n",
    "**Note**: This notebook is not executed as part of the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f361c04-4a7f-4b1f-ac22-dd91eaf112fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"NSE_Daily_Data\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"200\") \\\n",
    "    .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15f7f511-425a-43b6-9213-1b636106a658",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import (\n",
    "    col, sum, count, when, lit\n",
    ")\n",
    "spark_df = spark.read.table(\"workspace.NSE_SET.NIFTY50_DAILY\")\n",
    "# -----------------------------\n",
    "# 1. MARKET SUMMARY (1 ROW)\n",
    "# -----------------------------\n",
    "market_summary = spark_df.select(\n",
    "    count(\"*\").alias(\"total_stocks\"),\n",
    "    sum(when(col(\"change\") > 0, 1).otherwise(0)).alias(\"advancers\"),\n",
    "    sum(when(col(\"change\") < 0, 1).otherwise(0)).alias(\"decliners\"),\n",
    "    sum(when(col(\"change\") == 0, 1).otherwise(0)).alias(\"unchanged\"),\n",
    "    sum(\"totalTradedVolume\").alias(\"market_total_volume\"),\n",
    "    sum(\"totalTradedValue\").alias(\"market_total_value\")\n",
    ")\n",
    "\n",
    "summary = market_summary.collect()[0]\n",
    "\n",
    "# -----------------------------\n",
    "# 2. ENRICH STOCK DATA\n",
    "# -----------------------------\n",
    "final_df = spark_df \\\n",
    "    .withColumn(\"total_stocks\", lit(summary[\"total_stocks\"])) \\\n",
    "    .withColumn(\"advancers\", lit(summary[\"advancers\"])) \\\n",
    "    .withColumn(\"decliners\", lit(summary[\"decliners\"])) \\\n",
    "    .withColumn(\"unchanged\", lit(summary[\"unchanged\"])) \\\n",
    "    .withColumn(\"market_total_volume\", lit(summary[\"market_total_volume\"])) \\\n",
    "    .withColumn(\"market_total_value\", lit(summary[\"market_total_value\"])) \\\n",
    "    .withColumn(\"is_gainer\", when(col(\"pChange\") > 0, \"Y\").otherwise(\"N\")) \\\n",
    "    .withColumn(\"is_loser\", when(col(\"pChange\") < 0, \"Y\").otherwise(\"N\")) \\\n",
    "    .withColumn(\"high_volume_flag\", when(col(\"totalTradedVolume\") > 1_000_000, \"Y\").otherwise(\"N\")) \\\n",
    "    .withColumn(\"near_52w_high_flag\", when(col(\"nearWKH\") <= 2, \"Y\").otherwise(\"N\")) \\\n",
    "    .withColumn(\"near_52w_low_flag\", when(col(\"nearWKL\") <= 2, \"Y\").otherwise(\"N\"))\n",
    "\n",
    "# -----------------------------\n",
    "# 3. FINAL COLUMN SELECTION\n",
    "# -----------------------------\n",
    "report_df = final_df.select(\n",
    "    \"symbol\",\n",
    "    \"open\",\n",
    "    \"dayHigh\",\n",
    "    \"dayLow\",\n",
    "    \"lastPrice\",\n",
    "    \"previousClose\",\n",
    "    \"change\",\n",
    "    \"pChange\",\n",
    "    \"totalTradedVolume\",\n",
    "    \"totalTradedValue\",\n",
    "    \"yearHigh\",\n",
    "    \"yearLow\",\n",
    "    \"nearWKH\",\n",
    "    \"nearWKL\",\n",
    "    \"trade_date\",\n",
    "    \"load_date\",\n",
    "    \"is_gainer\",\n",
    "    \"is_loser\",\n",
    "    \"high_volume_flag\",\n",
    "    \"near_52w_high_flag\",\n",
    "    \"near_52w_low_flag\",\n",
    "    \"total_stocks\",\n",
    "    \"advancers\",\n",
    "    \"decliners\",\n",
    "    \"unchanged\",\n",
    "    \"market_total_volume\",\n",
    "    \"market_total_value\"\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 4. WRITE SINGLE CSV FILE\n",
    "# -----------------------------\n",
    "report_df.write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(\"workspace.NSE_SET.NIFTY50_DAILY_REPORT\")\n",
    "\n",
    "display(report_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e697863-970d-41b9-ae72-9847f9d4f3b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "dependencies": [
     "-r /Workspace/Users/girianiruddha4@gmail.com/stck_data/ml_stock_analysis/src/ml_stock_analysis_etl/requirements.txt"
    ],
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5638168664317539,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "st1_filter",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
